{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector stores and embeddings\n",
    "- Using embeddings and vector stores to convert splitted chunks into an index for easy retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vector store](https://python.langchain.com/assets/images/vector_stores-9dc1ecb68c4cb446df110764c9cc07e0.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PaLM API key\n",
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"./docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./docs/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"./docs/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"./docs/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "# loading the duplicate of 1st lecture pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docs = []\n",
    "for loader in loaders:\n",
    "    pdf_docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_docs[0].page_content[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, chunk_overlap=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(pdf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GooglePalm LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "embedding = GooglePalmEmbeddings(google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector store\n",
    "- using Chroma open-source vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./vector_database/chroma/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./vector_database/chroma\n",
    "# remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity search to ask query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email I can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \n",
      "rather than sending us email individually, if you send email to this account, it will \n",
      "actually let us get back to you maximally quickly with answers to your questions.  \n",
      "If you're asking questions about homework probl ems, please say in the subject line which \n",
      "assignment and which question the email refers to, since that will also help us to route \n",
      "your question to the appropriate TA or to me  appropriately and get the response back to \n",
      "you quickly.  \n",
      "Let's see. Skipping ahead — let's see — for homework, one midterm, one open and term \n",
      "project. Notice on the honor code. So one thi ng that I think will help you to succeed and \n",
      "do well in this class and even help you to enjoy this cla ss more is if you form a study \n",
      "group.  \n",
      "So start looking around where you' re sitting now or at the end of class today, mingle a \n",
      "little bit and get to know your classmates. I strongly encourage you to form study groups \n",
      "and sort of have a group of people to study with and have a group of your fellow students \n",
      "to talk over these concepts with. You can also  post on the class news group if you want to \n",
      "use that to try to form a study group.  \n",
      "But some of the problems sets in this cla ss are reasonably difficult.  People that have \n",
      "taken the class before may tell you they were very difficult. And just I bet it would be \n",
      "more fun for you, and you'd probably have a be tter learning experience if you form a\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Failure modes: some examples where similarity search can fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': './docs/MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': './docs/MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are identical chunks, semantic search fetches all similar documents, but does not enforce diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example\n",
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MachineLearning-Lecture03  \\nInstructor (Andrew Ng) :Okay. Good morning and welcome b ack to the thir'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Instructor (Andrew Ng) :All right, so who thought driving could be that dramatic, right? \\nSwitch bac'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': './docs/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 2, 'source': './docs/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 14, 'source': './docs/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 9, 'source': './docs/MachineLearning-Lecture02.pdf'}\n",
      "{'page': 0, 'source': './docs/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this to denote the predicted value of “by my hypothesis H” on the input XI. And my \n",
      "hypothesis was franchised by the vector of gram s as theta and so we said that this was \n",
      "equal to some from theta J, si J, and more  theta transpose X. And we had the convention \n",
      "that X subscript Z is equal to one so this accounts for the intercept term in our linear regression model. And lowercas e n here was the notation I was using for the number of \n",
      "features in my training set. Okay? So in  the example when trying to predict housing \n",
      "prices, we had two features, the size of the house and the number of bedrooms. We had \n",
      "two features and there was – li ttle n was equal to two. So just to finish recapping the \n",
      "previous lecture, we define d this quadratic cos function J of theta equals one-half, \n",
      "something I equals one to m, theta of XI mi nus YI squared where this is the sum over our \n",
      "m training examples and my training set. So lowercase m was the notation I’ve been \n",
      "using to denote the number of training exampl es I have and the size of my training set. \n",
      "And at the end of the last lecture, we deri ve the value of theta that minimizes this \n",
      "enclosed form, which was X transpose X inverse X transpose Y. Okay?  \n",
      "So as we move on in today’s lecture, I’ll cont inue to use this notation and, again, I realize \n",
      "this is a fair amount of notation to all reme mber, so if partway th rough this lecture you \n",
      "forgot – if you’re having trouble remembering what lowercase m is or what lowercase n\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR search: Maximal Marginal Relevance\n",
    "- retrieve both relevant and distinct chunks at the same time, getting the diverse information for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.max_marginal_relevance_search(question, k=3)[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplicity of this algorithm will let us come back and use it as a building block. Okay? \\nBut that’s'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.max_marginal_relevance_search(question, k=3)[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Student: [Inaudible]?  \\nInstructor (Andrew Ng) :Yeah, I threw a lot of notations  at you today. So M'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.max_marginal_relevance_search(question, k=3)[2].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The MMR results provide diverse information and differ from similarity search results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
